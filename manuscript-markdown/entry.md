# ログをはじめて取り込んで可視化する方たちへ

世の中にはたくさんのログがあり、いろんなかたちで携わっている方がいるのではないでしょうか。  
例えば、Webサービスのログから分析用途として使用したり、障害対応でログの調査を行ったり、様々あるかと思います。  
ログになんらかで携わったことがある人は、一度は面倒な作業だと思ったことはないでしょうか（僕はありますw）  
分析する場面までいければまだいいです。  
でも、現実は、まずログ自体の取得が非常に大変です。  
サーバが1台ならいいのですが、数十台になってきたら、ツラミでしかないです。  
あくまで一例ですが、どのような流れでログを取得して分析するまでやっているか見ていきたいと思います。

## ログ取得から分析までの流れ

仮にWebサーバ(Nginx)を4台運用しているとします。  
日々のアクセス状況を見たいため、access.logを取得したいと考えます。  

1. Webサーバにアクセスし、access.logをscpで取得します
2. Webサーバが4台あるため、1を4回繰り返します
3. 取得したaccess.logをマージします
4. マージしたログをExcelに展開します
5. Excelに展開したログを分析できるようレコードをカラム単位に分割できるよう加工します
6. 分析開始

さて、どうでしょうか。  
Excelで分析する前提でやりましたが、かなりの工数がかかることがわかるのではないでしょうか？  

いやいや、自動化できるところあるでしょ！って思う人もいると思います。  
たしかにシェル芸人の方やVBを駆使できる方がいれば可能です。  
ただ、取り込む際にバッチ処理で施すものなら、ログの鮮度は落ちてしまいます。  

では、もっと楽に取り込めて、ニアリアルタイムで分析できるログ基盤を構築することはできないのか。  
結論から言うと、できます。  
Elastic Stackを活用することで、これらを実現することができます。  

それではここからElastic Stackについて説明していきます。

## Elastic Stackについて

Elastic Stackは、Elasticsearch社が提供するプロダクトです。  
以前までは、ELKという言葉で、Elasticsearch、Logstash、Kibanaの頭文字をとった呼び名で親しまれていました。  
しかし、Beatsという新たなプロダクトが増えたことにより、ELKでは違和感があるのと、ELKにうまい具合にBを追加することも難しかったとのことです。  
そこで、Elastic Stackという名前に統合したかたちとなり、以下のプロダクトを含んでます。  

* Elasticsearch
* Logstash
* Kibana
* Beats

どんな用途で使われるものなのかを説明したいと思います。

### Elasticsearch

Elasticsaerchは、オープンソースの分散型RESTfull検索エンジンです。  
よく利用される用途としては、リアルタイムデータ分析、ログ解析、全文検索など様々なところで利用されてます。  
本書では、ログを取り込むストアとしてElasticsearchを利用します。  

### Logstash

Logstashは、オープンソースログ収集管理ツールです。  
インプット用のプラグインが豊富にあるため、様々なデータソースに対応できます。  
例えば、File、Kinesis、S3、Kafka..etc  
また、取得したログをフィールドを識別して構造化することも可能です。  
構造化したデータをElasticsearchやHadoopなどをアウトプット先とすることが可能です。  
このようにインプットしたデータを加工し、アウトプットするまでの一連の動作をLogstashは担っています。

### kibana

Kibanaは、オープンソースのビジュアライズツールです。  
Elasticsaerchに取り込んだデータをビジュアライズするためのツールです。  
直感的にわかりやすいUIからリアルタイムデータ分析やログ解析を実現させます。

### Beats

Beatsは、様々な用途に合わせてデータを容易に送ることができるオープンソースの軽量データシッパーです。  
目的別にエージェントが用意されており、それらをBeatsファミリーと言います。  
Beatsファミリーは、Filebeat、Metricbeat、Packetbeat、Winlogbeat、Auditbeat、Heartbeatの6つが用意されています。  
簡単にですが、どんな用途で使われるものなのかを説明します。

#### Filebeat

大量のサーバのログファイルなどのファイルをを一箇所に集約します。  
また、集約だけでなく、転送時にあらかじめ用意されたモジュールを利用することで、パース処理を施す必要がなく、ストアすることが可能です。  
さらに取り込んだデータをビジュアライズするための、ダッシュボードの作成も用意されているため、簡単に導入することができます。

#### Metricbeat

メトリックという名前だけあって、システムやサービスのメトリックすを収集することができます。  
例えば、サーバのCPUや、メモリの使用率から、ディスクIOなどのデータだけでなく、プロセスなども収集できます。  
また、ビジュアライズするためのダッシュボードもあらかじめ用意されているため、簡単に導入することが可能です。  

サービスについても、簡単に収集するためのモジュールが用意してあります。  
例えば、PostgreSQL、Dockerなど。

#### Packetbeat

ネットワークを流れるパケットを収集することができます。  
パケットを収集するときにWiresharkなどで取得する場面があると思いますが、より簡単に専門的な知識がなくてもビジュアライズまで可能するものです。  
様々なプロトコルに対応しているため、MySQLのクエリなどをビジュアライズすることも可能です。

#### Winlogbeat

Windowsのイベントログを収集することができます。  
例えば、Windowsサーバを運用しており、監査目的でログオンしたユーザを把握したい場合は、イベントIDの"ログオン: 4624"や"ログオン失敗: 4625"を指定するだけで、収集することが可能です。  
このように取得したいイベントIDを指定するだけなので、簡単に導入できます。  

#### Auditbeat

サーバの監査ログを収集することができます。  
通常、auditdのログを監査ログとして利用してい場合が多いと思いますが、Auditbeatを使用することで、必要な情報をグルーピングし、ストアすることができます。  
また、ダッシュボードも用意されているため、取り込んで、ビジュアライズまでを意識することなく導入ができます。

#### Heartbeat

サーバの稼働状況を監視することができます。  
ICMPでサーバの稼働状況を把握することも可能ですし、HTTPでサービス稼働も把握することが可能です。  
また、TLS、認証やプロキシにも対応しているため、あらゆる状況でも稼働状況を監視することができます。  

## 目的

ここまでElastic Stackについて説明しましたが、ここからは実際にElastic Stackに触れていきます。  
具体的には、ログの取り込み部分のLogstashとBeatsの二つのプロダクトを通じて、ログの取り込み方法の理解を深めたいと思います。  
主に以下についての理解を深めていけるようにします。  

* Logstashの使い方
* Beatsの使い方
* LogstashとBeatsの違い

### 実行環境について

Elastic Stackのバージョンは、以下を使用します。  

* Elasticsearch 6.2.2
* Logstash 6.2.2
* Kibana 6.2.2
* Metricbeat 6.2.2
* Auditbeat 6.2.2
* Packetbeat 6.2.2

> Download Elastic Stack  
> https://www.elastic.co/jp/products

サーバは、AWSのEC2を利用します。  
OSは、AmazonLinuxを利用し、インスタンスタイプは最低限必要なリソースを積んだものにします。

* Amazon Linux AMI 2017.09.1 (HVM), SSD Volume Type - ami-97785bed
* t2.medium(vCPU: 2,Mem: 4)
